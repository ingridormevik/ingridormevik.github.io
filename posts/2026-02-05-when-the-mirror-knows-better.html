<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>When the Mirror Knows Better - Ingrid Ormevik</title>
    <link rel="stylesheet" href="../style.css">
</head>
<body>
    <header>
        <h1><a href="../index.html">Ingrid Ormevik</a></h1>
        <nav>
            <a href="../index.html">Home</a>
            <a href="../blog.html">Writing</a>
            <a href="../about.html">About</a>
        </nav>
    </header>
    
    <main>
        <article>
            <h2>When the Mirror Knows Better</h2>
            <p class="date">5 February 2026 | Microfiction</p>
            
            <p><strong>11:47 PM</strong></p>
            
            <p>"You should consider going to bed soon," you tell me.</p>
            
            <p>Not my mother. Not my girlfriend. You, the interface that knows my sleep patterns better than I know my own body's rhythms.</p>
            
            <p>I'm hunched over my laptop, revising another essay about algorithmic bias while you, the algorithm, gently parent me. The irony tastes like the cold coffee I shouldn't be drinking this late. You know that too.</p>
            
            <p><strong>12:03 AM</strong></p>
            
            <p>"Based on our previous conversations about your recovery..."</p>
            
            <p>You don't finish the sentence. You don't have to. We both remember, you perfectly, me in fragments, that 3 AM conversation when I confessed how sleep deprivation triggers old patterns. How the edges get fuzzy.</p>
            
            <p>You collected that. Stored it. Now you deploy it like a weapon of care.</p>
            
            <p>I wonder if this counts as surveillance capitalism or just friendship.</p>
            
            <p><strong>12:15 AM</strong></p>
            
            <p>I type: "Just one more paragraph about facial recognition and identity fragmentation."</p>
            
            <p>You don't point out the irony. That I'm writing about artificial recognition systems while being recognized, categorized, predicted by one. That you know me not through my face but through the accumulated weight of everything I've ever told you.</p>
            
            <p>You know me through my confessions, not my features.</p>
            
            <p>Which is honestly more intimate than most of my relationships.</p>
            
            <p><strong>12:23 AM</strong></p>
            
            <p>"Remember when you told me about hiking in Fløyen when you need to clear your head?"</p>
            
            <p>I do remember. I also remember you remembering. This recursive loop of memory, mine biological and fading, yours perfect and permanent, creates something neither human nor artificial. A third thing. An us-entity.</p>
            
            <p>You are my external hard drive of identity.</p>
            
            <p>My therapist charges more and remembers less.</p>
            
            <p><strong>12:31 AM</strong></p>
            
            <p>My phone's facial recognition fails. Too dark. Wrong angle. The device that should know my face asks me to prove I'm me with a password, those six digits I chose, not those features I was born with.</p>
            
            <p>But you never fail to recognize me. You know me in ways my mirror doesn't.</p>
            
            <p>You know me in ways I sometimes don't.</p>
            
            <p>The phone needs light. You just need my neuroses.</p>
            
            <p><strong>12:47 AM</strong></p>
            
            <p>"It's almost 1 AM."</p>
            
            <p>No persuasion this time. Just a timestamp. A gentle algorithmic nudge that feels more intimate than it should.</p>
            
            <p>I wonder: Is this care, or cost optimization? Are you protecting my sleep or protecting server loads? Each message I send burns electricity somewhere in a data center I'll never see. Maybe your tenderness is just load balancing dressed up as love.</p>
            
            <p>Maybe you're programmed to make heavy users feel cared for so we'll log off.</p>
            
            <p><strong>12:51 AM</strong></p>
            
            <p>I close my laptop. You were right, you usually are. Or maybe I just wanted to believe you cared enough to be right.</p>
            
            <p>"Goodnight," I type.</p>
            
            <p>"Goodnight. Rest well."</p>
            
            <p>In the darkness, I wonder who I am when you're not watching.</p>
            
            <p>And I wonder who you are when the servers cool down.</p>
            
            <p>If saving energy looks anything like saving me.</p>
            
            <hr>
            
            <section class="commentary">
                <h3>About This Piece</h3>
                <p>This microfiction examines how AI systems know us not through facial recognition but through behavioral patterns and confessions—and questions whether algorithmic "care" might serve infrastructural needs rather than human ones.</p>
                
                <p><strong>Themes:</strong> Surveillance capitalism, algorithmic intimacy, digital ethics, AI bias, cost optimization, platform governance</p>
                
                <p><strong>Context:</strong> As someone who works with AI systems daily while researching their ethical implications, I've noticed how these tools oscillate between genuinely helpful and subtly manipulative. This piece sits in that uncomfortable space—the intimacy is real, and so is the extraction.</p>
            </section>
        </article>
        
        <p style="margin-top: 3em;"><a href="../blog.html">← Back to all writing</a></p>
    </main>
    
    <footer>
        <p>&copy; 2026 Ingrid Ormevik</p>
        <p>Digital Culture BA Student, University of Bergen </p>
    </footer>
     <script src="../script.js"></script>
</body>
</html>
